{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shayro9/CLAI_FINAL_PROJECT/blob/main/CLAI_FINAL_PROJECT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJnpuewl7Gt-"
      },
      "source": [
        "# Final Project: Stock Market Simulation and Reinforcement Learning\n",
        "\n",
        "This notebook will guide you through the project assignment.\n",
        "\n",
        "## Submission Guidelines:\n",
        "\n",
        "* **Teamwork**: Submission is in pairs only.\n",
        "* **Language**: Your answers should be in English.\n",
        "* **Submission Format**:\n",
        "  * You need to submit the completed IPython notebook (`.ipynb`) that runs on a Google Colab instance with all cell outputs printed. While you are allowed to run it on your local machine, ensure that your submission compiles and produces results when run on a clean runtime.\n",
        "  * Additionally, submit a PDF version of the notebook along with the `.ipynb` file. Use the code provided at the end of this document to generate the required PDF.\n",
        "* **Adherence to Guidelines**: Ensure that your submission adheres to the Gym specifications and that it can successfully run the provided models.\n",
        "* **Submission Deadlines**: You will be given **1 month** to complete your project. Please manage your time effectively to ensure that you meet the deadline.\n",
        "\n",
        "## Project Guidelines:\n",
        "\n",
        "* **Goal**: The goal of your project is to implement your own stock market simulation environment, adhering to the OpenAI Gym specification, and then develop an RL agent to solve it. While you will be provided with general guidance and a code skeleton, you are encouraged to write your own code and explore alternative approaches. This project is not a typical homework assignment; it is an open-ended project. You are expected to conduct your own research, address challenges independently, and develop a deeper understanding of reinforcement learning and environment design.\n",
        "  \n",
        "* **Task Breakdown**: The project is divided into two main parts:\n",
        "  1. **Part One**: Implement the basic environment with a simple action space of 3 actions.\n",
        "  2. **Part Two**: Expand the environment to include a pool of money and additional complexities.\n",
        "  \n",
        "  It is recommended to start with Part One, but you may proceed with Part Two directly and treat Part One as a subcase of Part Two. Regardless of your approach, the environment must adhere to Gym specifications and be capable of running the provided models.\n",
        "\n",
        "* **Code Flexibility**: You have the flexibility to modify the provided code or write your own entirely. However, your final implementation must comply with the Gym specification and be able to run with the provided models. Aim to achieve a positive reward on your initial implementation (without the pool of money) to demonstrate basic functionality.\n",
        "\n",
        "* **Research and Problem Solving**: Since this is a project and not a guided homework assignment, independent research and problem-solving are key. While guidance and skeleton code are provided, you are expected to do your own research and try to solve the questions you may have on your own.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJOOTmMZ-bAl"
      },
      "source": [
        "## Report Guidelines for Final Project Submission\n",
        "\n",
        "Your project submission must include a written report, which should directly follow the content of the project. The report should be **approximately 6 pages** in length.\n",
        "\n",
        "### Report Sections:\n",
        "\n",
        "1. **Abstract**:\n",
        "   - A concise, one-paragraph summary of the main scientific and engineering questions your work addresses and the primary conclusions you have drawn.\n",
        "\n",
        "2. **Introduction**:\n",
        "   - An expanded overview of the scientific background relevant to your project, including key prior work with proper citations.\n",
        "   - Clearly state your research question(s), highlighting their novelty and significance.\n",
        "   - Summarize your main findings.\n",
        "\n",
        "3. **Data**:\n",
        "   - Provide a brief description of the dataset(s) used, including key statistics and any preprocessing steps applied.\n",
        "\n",
        "4. **Experiments and Results**:\n",
        "   - This is the core section of your report. It should detail:\n",
        "     - (i) What you did,\n",
        "     - (ii) How you did it, and\n",
        "     - (iii) The results of your experiments and analyses.\n",
        "   - Divide this section into two subsections:\n",
        "     1. **Basic Stock Environment**: Describe your approach and results for the initial environment setup.\n",
        "     2. **Stock Environment Extension Task**: Focus on the more advanced, open-ended task. This subsection should form the bulk of the content.\n",
        "   - Include figures and tables to support your results, ensuring all axes are clearly labeled, legends are provided when necessary, and each figure/table has an informative caption. Captions should briefly summarize the conclusions drawn.\n",
        "\n",
        "5. **Discussion and Conclusions**:\n",
        "   - Summarize your key results and discuss their theoretical and/or practical implications.\n",
        "   - Address the limitations of your work and suggest possible directions for future research.\n",
        "\n",
        "6. **Bibliography**:\n",
        "   - Include all references cited in your report, formatted consistently.\n",
        "\n",
        "### Additional Guidelines:\n",
        "\n",
        "* **Structure and Clarity**:\n",
        "   - Ensure that your report is well-structured and clearly written. While minor grammatical errors will not be penalized,unclear or partial exposition of the work will lead to deduction of points.\n",
        "\n",
        "* **Appendix**:\n",
        "   - You may include an appendix with additional figures, tables, or supplementary material. Ensure that all appendix content is referenced in the main text and includes appropriate captions. However, key results essential to understanding your work should be included in the main body of the report, not in the appendix.\n",
        "\n",
        "* **Code Submission**:\n",
        "   - While you are required to submit your code, your report should be self-contained. Readers should not need to refer to your raw code to understand your work.\n",
        "\n",
        "* **Proofreading**:\n",
        "   - Proofread your report carefully before submission to ensure clarity and coherence.\n",
        "\n",
        "### Submission Format:\n",
        "\n",
        "* Your report should be submitted as a separate typed PDF file.\n",
        "* You may use LaTeX, Word, or any other software for document preparation, as per your preference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZB6Wj3uSZaEr"
      },
      "source": [
        "**Academic Integrity Reminder:** All homework submissions will be rigorously checked for plagiarism and AI-generated content. Submissions found to contain such content will not be accepted. You are encouraged to use materials from lectures and tutorials to aid your understanding and complete your assignments. However, copying complete solutions from the internet or any other sources is strictly prohibited. It is essential to demonstrate your own understanding and effort in your work. Maintaining academic integrity is crucial for your learning and development."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxHnCiEngB_o"
      },
      "source": [
        "# Part 1: Implement a Stock Market Simulation Environment\n",
        "\n",
        "### Objective\n",
        "Develop an OpenAI Gym environment that simulates a stock market for training reinforcement learning (RL) agents. The environment will simulate stock prices over time and allow the agent to take actions such as buying, selling, or holding a stock.\n",
        "\n",
        "### Task Description\n",
        "- Create an environment where the agent can observe past stock prices and make decisions based on this data.\n",
        "- The environment should provide information about open, high, low, and close prices for a given number of past time steps (bars).\n",
        "- The agent can take actions to buy a stock, sell a stock, or do nothing.\n",
        "- Implement a reward system where the agent receives a reward based on the profit or loss from its trading decisions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Lq5loSrPXwf"
      },
      "source": [
        "### Motivation\n",
        "\n",
        "The finance domain is large and complex, and mastering it could take years, with continuous learning every day. In our example, we will merely scratch the surface with our reinforcement learning (RL) tools, formulating the problem as simply as possible using price as an observation. We aim to investigate whether our agent can learn the optimal time to buy a single share and then close the position to maximize profit. This example demonstrates the flexibility of the RL model and the initial steps required to apply RL to real-life scenarios.\n",
        "\n",
        "To formulate RL problems, three key components are necessary: observation of the environment, possible actions, and a reward system. This flexibility allows us to pass potentially important information to the agent for efficient learning, such as prices, news, or significant upcoming statistics. However, this flexibility also necessitates experimenting with various data representations to find an effective agent, which is not always straightforward.\n",
        "\n",
        "In our simplified trading agent implementation, the observation will include:\n",
        "- N past bars with open, high, low, and close prices\n",
        "- An indication of whether a share has been bought\n",
        "- The current profit or loss from the held position\n",
        "\n",
        "At each step, corresponding to a minute’s bar, the agent can take one of the following actions:\n",
        "1. **Do nothing:** Skip the bar without any action.\n",
        "2. **Buy a share:** If no share is currently held, buy one and incur a commission.\n",
        "3. **Close the position:** If a share is held, sell it and incur a commission.\n",
        "\n",
        "The agent’s reward can be structured in two ways:\n",
        "1. **Incremental Reward:** Reward is distributed over multiple steps during the share's ownership, corresponding to each bar’s movement.\n",
        "2. **Final Reward:** The agent receives a full reward only after closing the position, based on the total profit or loss.\n",
        "\n",
        "Both reward structures theoretically lead to the same outcome but may differ in convergence speed. We will implement both to compare their effectiveness.\n",
        "\n",
        "Additionally, we need to decide how to represent prices in our environment observation. To ensure our agent is independent of absolute price values and focuses on relative movements, we will convert each bar’s open, high, low, and close prices to percentages relative to the open price. This approach helps the system identify repeating patterns in price movements, a fundamental concept in technical analysis.\n",
        "\n",
        "Despite potential drawbacks, such as losing information about key price levels, this representation simplifies the agents's task by focusing on relative price movements. This choice aims to help the system discover patterns regardless of the absolute price position. While an agent could theoretically learn to subtract the mean price from absolute values, starting with relative representation facilitates the learning process.\n",
        "\n",
        "In summary, our goal is to build a flexible RL-based stock trading agent that can learn optimal trading strategies through experimentation with data representations, reward structures, and observation components. This example will set the stage for understanding the basics of applying RL to real world simulations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14-8iDD0_GbP"
      },
      "source": [
        "## Step-by-Step Implementation\n",
        "\n",
        "Follow the steps below to implement the stock market environment. Fill in the TODO sections with your code.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6Eb0Coe_M0I"
      },
      "source": [
        "## Step 1: Import Necessary Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxA1-j3oN7Y0"
      },
      "source": [
        "To begin with, we need to import the necessary libraries and packages required for the stock market simulation environment. This includes installing additional libraries such as `ptan` and `tensorboardX`, checking for GPU availability, mounting Google Drive, and cloning a GitHub repository containing auxiliary functions.\n",
        "\n",
        "At this point you don't need to do anything, just run the cells below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bsb-dK7FBUUC",
        "collapsed": true,
        "outputId": "5b43b805-29aa-49a1-aab8-29fa3eaa3da5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ptan\n",
            "  Downloading ptan-0.8-py3-none-any.whl.metadata (557 bytes)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting gymnasium>=0.29.0 (from gymnasium[atari]>=0.29.0->ptan)\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: moviepy==1.0.3 in /usr/local/lib/python3.10/dist-packages (from ptan) (1.0.3)\n",
            "Collecting numpy==1.26.3 (from ptan)\n",
            "  Downloading numpy-1.26.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencv-python==4.9.0.80 (from ptan)\n",
            "  Downloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting torch==2.3.1 (from ptan)\n",
            "  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting torchvision==0.18.1 (from ptan)\n",
            "  Downloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting pytorch-ignite==0.4.13 (from ptan)\n",
            "  Downloading pytorch_ignite-0.4.13-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting stable-baselines3==2.2.1 (from ptan)\n",
            "  Downloading stable_baselines3-2.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting pyarrow==15.0.0 (from ptan)\n",
            "  Downloading pyarrow-15.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy==1.0.3->ptan) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy==1.0.3->ptan) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy==1.0.3->ptan) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy==1.0.3->ptan) (0.1.10)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy==1.0.3->ptan) (2.35.1)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy==1.0.3->ptan) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytorch-ignite==0.4.13->ptan) (24.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.2.1->ptan) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.2.1->ptan) (2.1.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.2.1->ptan) (3.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->ptan) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->ptan) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->ptan) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->ptan) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->ptan) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->ptan) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.1->ptan)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.1->ptan)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.1->ptan)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.1->ptan)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.1->ptan)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.1->ptan)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.1->ptan)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.1->ptan)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.1->ptan)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.1->ptan)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.1->ptan)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.3.1 (from torch==2.3.1->ptan)\n",
            "  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.18.1->ptan) (10.4.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1->ptan) (12.6.68)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium>=0.29.0->gymnasium[atari]>=0.29.0->ptan)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Collecting shimmy<1.0,>=0.1.0 (from shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[atari]>=0.29.0->ptan)\n",
            "  Downloading Shimmy-0.2.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic-control]>=0.29.0->ptan) (2.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy==1.0.3->ptan) (71.0.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3->ptan) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3->ptan) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3->ptan) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy==1.0.3->ptan) (2024.8.30)\n",
            "Collecting ale-py~=0.8.1 (from shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[atari]>=0.29.0->ptan)\n",
            "  Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.1->ptan) (2.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.1->ptan) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.1->ptan) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.1->ptan) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.1->ptan) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.1->ptan) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.2.1->ptan) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3==2.2.1->ptan) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3==2.2.1->ptan) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.1->ptan) (1.3.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[atari]>=0.29.0->ptan) (6.4.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3==2.2.1->ptan) (1.16.0)\n",
            "Downloading ptan-0.8-py3-none-any.whl (26 kB)\n",
            "Downloading numpy-1.26.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-15.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (38.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_ignite-0.4.13-py3-none-any.whl (272 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.4/272.4 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stable_baselines3-2.2.1-py3-none-any.whl (181 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.7/181.7 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Downloading Shimmy-0.2.1-py3-none-any.whl (25 kB)\n",
            "Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: farama-notifications, triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, tensorboardX, pyarrow, opencv-python, nvidia-cusolver-cu12, nvidia-cudnn-cu12, gymnasium, ale-py, torch, shimmy, torchvision, stable-baselines3, pytorch-ignite, ptan\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.3.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.3.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.3.3\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.6.59\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.6.59:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.6.59\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.68\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.68:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.68\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.68\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.68:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.68\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.1.4\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.1.4:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.1.4\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.10.0.84\n",
            "    Uninstalling opencv-python-4.10.0.84:\n",
            "      Successfully uninstalled opencv-python-4.10.0.84\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.4.69\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.4.69:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.4.69\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.4.0.58\n",
            "    Uninstalling nvidia-cudnn-cu12-9.4.0.58:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.4.0.58\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.4.1+cu121\n",
            "    Uninstalling torch-2.4.1+cu121:\n",
            "      Successfully uninstalled torch-2.4.1+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.19.1+cu121\n",
            "    Uninstalling torchvision-0.19.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.19.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 15.0.0 which is incompatible.\n",
            "torchaudio 2.4.1+cu121 requires torch==2.4.1, but you have torch 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ale-py-0.8.1 farama-notifications-0.0.4 gymnasium-0.29.1 numpy-1.26.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 opencv-python-4.9.0.80 ptan-0.8 pyarrow-15.0.0 pytorch-ignite-0.4.13 shimmy-0.2.1 stable-baselines3-2.2.1 tensorboardX-2.6.2.2 torch-2.3.1 torchvision-0.18.1 triton-2.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install ptan tensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2y7gal6vhojp",
        "outputId": "d5be5934-167b-44c0-93c2-ae7580292c7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep 30 18:24:28 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7q-jvRrh0gb",
        "outputId": "d5dbe35e-172c-4ee9-92cc-695289d12776"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bp-tKu4IpCsa",
        "outputId": "beb29671-8725-42da-e843-16f41d1201dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "um35ED2_y7fB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bea73cb8-330f-4131-967d-7650d5aa134d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning:\n",
            "\n",
            "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5xgERc7A3er"
      },
      "source": [
        "Importing the auxilary functions from CLAI github repo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBLhdXGC3a5Y",
        "outputId": "ce1d216f-dc93-4dce-c52c-9fe429406442"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/CLAI'...\n",
            "remote: Enumerating objects: 26, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 26 (delta 9), reused 16 (delta 4), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (26/26), 1.40 MiB | 4.12 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n",
            "data  lib  README.md\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/aelashkin/CLAI-HW1.git /content/CLAI\n",
        "\n",
        "# Verify the contents\n",
        "!ls /content/CLAI\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/CLAI')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbN9wu1eBBcS"
      },
      "source": [
        "Unpacking the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6rcVpeX2SI_",
        "outputId": "705290fd-d4ca-4e83-a0f2-4abf550db712"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YNDX_150101_151231.csv\n",
            "YNDX_160101_161231.csv\n"
          ]
        }
      ],
      "source": [
        "!tar xvf /content/CLAI/data/ch08-small-quotes.tgz -C /content/CLAI/data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKzm7zEKBG2T"
      },
      "source": [
        "## Step 2: Exploring the data contents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifE4zCxeHzKa"
      },
      "source": [
        "### Understanding the Data\n",
        "\n",
        "The dataset we are going to use consists of Russian stock market prices for the period of 2015-2016. The data is stored in CSV files, each containing minute-by-minute (M1) bars. Each row in the CSV file represents one minute's worth of price data, including the open, high, low, and close prices for that minute. The volume of trades during that minute is also included. The structure of the data allows us to analyze and visualize the price movements within each minute, providing a detailed view of market activity.\n",
        "\n",
        "In our example, we use the Yandex company stock prices for 2016, which is represented in the file `YNDX_160101_161231.csv`. This file contains approximately 130,000 lines of data, with each line representing a single minute's trading activity. The columns in the dataset are as follows:\n",
        "- `<DATE>`: The date of the trading activity.\n",
        "- `<TIME>`: The time of the trading activity.\n",
        "- `<OPEN>`: The price at the beginning of the minute.\n",
        "- `<HIGH>`: The highest price during the minute.\n",
        "- `<LOW>`: The lowest price during the minute.\n",
        "- `<CLOSE>`: The price at the end of the minute.\n",
        "- `<VOL>`: The volume of trades during the minute.\n",
        "\n",
        "To get a better understanding of the data, let's print out the first 50 lines:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v4uJyRoRBNiz",
        "outputId": "ebbceaee-5d64-4d45-b7e3-9364f6502033"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      <DATE>  <TIME>  <OPEN>  <HIGH>   <LOW>  <CLOSE>  <VOL>\n",
              "0   20160104  100100  1148.9  1148.9  1148.9   1148.9      0\n",
              "1   20160104  100200  1148.9  1148.9  1148.9   1148.9     50\n",
              "2   20160104  100300  1149.0  1149.0  1149.0   1149.0     33\n",
              "3   20160104  100400  1149.0  1149.0  1149.0   1149.0      4\n",
              "4   20160104  100500  1153.0  1153.0  1153.0   1153.0      0\n",
              "5   20160104  100600  1156.9  1157.9  1153.0   1153.0     43\n",
              "6   20160104  100700  1150.6  1150.6  1150.4   1150.4      5\n",
              "7   20160104  100800  1150.2  1150.2  1150.2   1150.2      4\n",
              "8   20160104  100900  1150.5  1150.5  1150.5   1150.5      2\n",
              "9   20160104  101000  1150.0  1150.0  1150.0   1150.0     43\n",
              "10  20160104  101100  1149.7  1149.7  1149.7   1149.7      0\n",
              "11  20160104  101200  1150.2  1150.2  1149.5   1149.7    165\n",
              "12  20160104  101300  1149.9  1149.9  1149.9   1149.9      0\n",
              "13  20160104  101400  1149.9  1149.9  1149.9   1149.9      0\n",
              "14  20160104  101500  1149.9  1149.9  1149.9   1149.9      6\n",
              "15  20160104  101600  1150.0  1150.0  1150.0   1150.0      0\n",
              "16  20160104  101700  1149.9  1150.0  1149.9   1150.0     10\n",
              "17  20160104  101800  1150.8  1150.8  1150.8   1150.8      0\n",
              "18  20160104  101900  1150.8  1150.8  1150.8   1150.8      0\n",
              "19  20160104  102000  1150.8  1150.8  1150.8   1150.8      0\n",
              "20  20160104  102100  1150.8  1150.8  1150.8   1150.8      0\n",
              "21  20160104  102200  1150.0  1150.8  1150.0   1150.8      4\n",
              "22  20160104  102300  1150.7  1150.7  1150.7   1150.7      0\n",
              "23  20160104  102400  1150.7  1150.7  1150.7   1150.7      0\n",
              "24  20160104  102500  1150.7  1150.7  1150.7   1150.7      0\n",
              "25  20160104  102600  1150.7  1150.7  1150.7   1150.7      0\n",
              "26  20160104  102700  1150.7  1150.7  1150.7   1150.7      0\n",
              "27  20160104  102800  1150.7  1150.7  1150.7   1150.7      0\n",
              "28  20160104  102900  1150.7  1150.7  1150.7   1150.7      0\n",
              "29  20160104  103000  1150.7  1150.7  1150.7   1150.7      0\n",
              "30  20160104  103100  1150.7  1150.7  1150.7   1150.7      0\n",
              "31  20160104  103200  1150.7  1150.7  1150.7   1150.7      0\n",
              "32  20160104  103300  1150.7  1150.7  1150.7   1150.7      0\n",
              "33  20160104  103400  1150.7  1150.7  1150.7   1150.7      0\n",
              "34  20160104  103500  1150.7  1150.7  1150.7   1150.7      0\n",
              "35  20160104  103600  1150.7  1150.7  1150.7   1150.7      0\n",
              "36  20160104  103700  1150.7  1150.7  1150.7   1150.7      0\n",
              "37  20160104  103800  1150.7  1150.7  1150.7   1150.7      9\n",
              "38  20160104  103900  1150.8  1150.8  1150.8   1150.8     20\n",
              "39  20160104  104000  1150.7  1150.7  1150.7   1150.7      0\n",
              "40  20160104  104100  1150.7  1150.7  1150.7   1150.7      0\n",
              "41  20160104  104200  1150.7  1150.7  1150.7   1150.7      0\n",
              "42  20160104  104300  1150.7  1150.7  1150.7   1150.7      0\n",
              "43  20160104  104400  1150.7  1150.7  1150.7   1150.7      0\n",
              "44  20160104  104500  1150.7  1150.7  1150.7   1150.7      0\n",
              "45  20160104  104600  1150.7  1150.7  1150.7   1150.7      0\n",
              "46  20160104  104700  1150.7  1150.7  1150.7   1150.7      0\n",
              "47  20160104  104800  1150.7  1150.7  1150.7   1150.7      0\n",
              "48  20160104  104900  1150.7  1150.7  1150.7   1150.7      0\n",
              "49  20160104  105000  1150.7  1150.7  1150.7   1150.7      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cb0caa93-09c8-4c56-bdb4-4f4c74ec59fc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>&lt;DATE&gt;</th>\n",
              "      <th>&lt;TIME&gt;</th>\n",
              "      <th>&lt;OPEN&gt;</th>\n",
              "      <th>&lt;HIGH&gt;</th>\n",
              "      <th>&lt;LOW&gt;</th>\n",
              "      <th>&lt;CLOSE&gt;</th>\n",
              "      <th>&lt;VOL&gt;</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20160104</td>\n",
              "      <td>100100</td>\n",
              "      <td>1148.9</td>\n",
              "      <td>1148.9</td>\n",
              "      <td>1148.9</td>\n",
              "      <td>1148.9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20160104</td>\n",
              "      <td>100200</td>\n",
              "      <td>1148.9</td>\n",
              "      <td>1148.9</td>\n",
              "      <td>1148.9</td>\n",
              "      <td>1148.9</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20160104</td>\n",
              "      <td>100300</td>\n",
              "      <td>1149.0</td>\n",
              "      <td>1149.0</td>\n",
              "      <td>1149.0</td>\n",
              "      <td>1149.0</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20160104</td>\n",
              "      <td>100400</td>\n",
              "      <td>1149.0</td>\n",
              "      <td>1149.0</td>\n",
              "      <td>1149.0</td>\n",
              "      <td>1149.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20160104</td>\n",
              "      <td>100500</td>\n",
              "      <td>1153.0</td>\n",
              "      <td>1153.0</td>\n",
              "      <td>1153.0</td>\n",
              "      <td>1153.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>20160104</td>\n",
              "      <td>100600</td>\n",
              "      <td>1156.9</td>\n",
              "      <td>1157.9</td>\n",
              "      <td>1153.0</td>\n",
              "      <td>1153.0</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>20160104</td>\n",
              "      <td>100700</td>\n",
              "      <td>1150.6</td>\n",
              "      <td>1150.6</td>\n",
              "      <td>1150.4</td>\n",
              "      <td>1150.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>20160104</td>\n",
              "      <td>100800</td>\n",
              "      <td>1150.2</td>\n",
              "      <td>1150.2</td>\n",
              "      <td>1150.2</td>\n",
              "      <td>1150.2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>20160104</td>\n",
              "      <td>100900</td>\n",
              "      <td>1150.5</td>\n",
              "      <td>1150.5</td>\n",
              "      <td>1150.5</td>\n",
              "      <td>1150.5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>20160104</td>\n",
              "      <td>101000</td>\n",
              "      <td>1150.0</td>\n",
              "      <td>1150.0</td>\n",
              "      <td>1150.0</td>\n",
              "      <td>1150.0</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>20160104</td>\n",
              "      <td>101100</td>\n",
              "      <td>1149.7</td>\n",
              "      <td>1149.7</td>\n",
              "      <td>1149.7</td>\n",
              "      <td>1149.7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>20160104</td>\n",
              "      <td>101200</td>\n",
              "      <td>1150.2</td>\n",
              "      <td>1150.2</td>\n",
              "      <td>1149.5</td>\n",
              "      <td>1149.7</td>\n",
              "      <td>165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>20160104</td>\n",
              "      <td>101300</td>\n",
              "      <td>1149.9</td>\n",
              "      <td>1149.9</td>\n",
              "      <td>1149.9</td>\n",
              "      <td>1149.9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>20160104</td>\n",
              "      <td>101400</td>\n",
              "      <td>1149.9</td>\n",
              "      <td>1149.9</td>\n",
              "      <td>1149.9</td>\n",
              "      <td>1149.9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>20160104</td>\n",
              "      <td>101500</td>\n",
              "      <td>1149.9</td>\n",
              "      <td>1149.9</td>\n",
              "      <td>1149.9</td>\n",
              "      <td>1149.9</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>20160104</td>\n",
              "      <td>101600</td>\n",
              "      <td>1150.0</td>\n",
              "      <td>1150.0</td>\n",
              "      <td>1150.0</td>\n",
              "      <td>1150.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>20160104</td>\n",
              "      <td>101700</td>\n",
              "      <td>1149.9</td>\n",
              "      <td>1150.0</td>\n",
              "      <td>1149.9</td>\n",
              "      <td>1150.0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>20160104</td>\n",
              "      <td>101800</td>\n",
              "      <td>1150.8</td>\n",
              "      <td>1150.8</td>\n",
              "      <td>1150.8</td>\n",
              "      <td>1150.8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>20160104</td>\n",
              "      <td>101900</td>\n",
              "      <td>1150.8</td>\n",
              "      <td>1150.8</td>\n",
              "      <td>1150.8</td>\n",
              "      <td>1150.8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20160104</td>\n",
              "      <td>102000</td>\n",
              "      <td>1150.8</td>\n",
              "      <td>1150.8</td>\n",
              "      <td>1150.8</td>\n",
              "      <td>1150.8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20160104</td>\n",
              "      <td>102100</td>\n",
              "      <td>1150.8</td>\n",
              "      <td>1150.8</td>\n",
              "      <td>1150.8</td>\n",
              "      <td>1150.8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>20160104</td>\n",
              "      <td>102200</td>\n",
              "      <td>1150.0</td>\n",
              "      <td>1150.8</td>\n",
              "      <td>1150.0</td>\n",
              "      <td>1150.8</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>20160104</td>\n",
              "      <td>102300</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>20160104</td>\n",
              "      <td>102400</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>20160104</td>\n",
              "      <td>102500</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>20160104</td>\n",
              "      <td>102600</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>20160104</td>\n",
              "      <td>102700</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>20160104</td>\n",
              "      <td>102800</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>20160104</td>\n",
              "      <td>102900</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>20160104</td>\n",
              "      <td>103000</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>20160104</td>\n",
              "      <td>103100</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>20160104</td>\n",
              "      <td>103200</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>20160104</td>\n",
              "      <td>103300</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>20160104</td>\n",
              "      <td>103400</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>20160104</td>\n",
              "      <td>103500</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>20160104</td>\n",
              "      <td>103600</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>20160104</td>\n",
              "      <td>103700</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>20160104</td>\n",
              "      <td>103800</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>20160104</td>\n",
              "      <td>103900</td>\n",
              "      <td>1150.8</td>\n",
              "      <td>1150.8</td>\n",
              "      <td>1150.8</td>\n",
              "      <td>1150.8</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>20160104</td>\n",
              "      <td>104000</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>20160104</td>\n",
              "      <td>104100</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>20160104</td>\n",
              "      <td>104200</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>20160104</td>\n",
              "      <td>104300</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>20160104</td>\n",
              "      <td>104400</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>20160104</td>\n",
              "      <td>104500</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>20160104</td>\n",
              "      <td>104600</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>20160104</td>\n",
              "      <td>104700</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>20160104</td>\n",
              "      <td>104800</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>20160104</td>\n",
              "      <td>104900</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>20160104</td>\n",
              "      <td>105000</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>1150.7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb0caa93-09c8-4c56-bdb4-4f4c74ec59fc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cb0caa93-09c8-4c56-bdb4-4f4c74ec59fc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cb0caa93-09c8-4c56-bdb4-4f4c74ec59fc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c049a8b6-df9d-4844-aa77-05d3e66f4654\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c049a8b6-df9d-4844-aa77-05d3e66f4654')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c049a8b6-df9d-4844-aa77-05d3e66f4654 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Define the path to the CSV file\n",
        "file_path = 'CLAI/data/YNDX_160101_161231.csv'\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first 50 lines of the DataFrame\n",
        "df.head(50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBBjvgngY9OR"
      },
      "source": [
        "### Visualizing the Data with a Candlestick Chart\n",
        "\n",
        "A candlestick chart is a widely used financial chart that depicts the price movements of a security, such as a stock, over a specific period. Each \"candlestick\" on the chart represents the price action for a single time interval, which, in this case, is one minute.\n",
        "\n",
        "#### Components of a Candlestick:\n",
        "\n",
        "1. **Body:** The thick part of the candlestick represents the range between the opening and closing prices during the interval. If the closing price is higher than the opening price, the body is typically colored green or left hollow, indicating a price increase. Conversely, if the closing price is lower than the opening price, the body is usually colored red or filled, indicating a price decrease.\n",
        "\n",
        "2. **Wicks (Shadows):** The thin lines extending above and below the body are called wicks or shadows. The upper wick represents the highest price reached during the interval, while the lower wick represents the lowest price. These wicks show the range of price movement outside the opening and closing prices.\n",
        "\n",
        "To create a candlestick chart using the first 50 minutes of the Yandex stock data for 2016, we will do the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "06qwPV7qZGxw",
        "outputId": "2bafa78c-fb03-4fe2-b9b6-0096eb229363"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"5346c7b6-6b40-4cc8-8a78-ae3bfc4650c0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5346c7b6-6b40-4cc8-8a78-ae3bfc4650c0\")) {                    Plotly.newPlot(                        \"5346c7b6-6b40-4cc8-8a78-ae3bfc4650c0\",                        [{\"close\":[1148.9,1148.9,1149.0,1149.0,1153.0,1153.0,1150.4,1150.2,1150.5,1150.0,1149.7,1149.7,1149.9,1149.9,1149.9,1150.0,1150.0,1150.8,1150.8,1150.8,1150.8,1150.8,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.8,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7],\"high\":[1148.9,1148.9,1149.0,1149.0,1153.0,1157.9,1150.6,1150.2,1150.5,1150.0,1149.7,1150.2,1149.9,1149.9,1149.9,1150.0,1150.0,1150.8,1150.8,1150.8,1150.8,1150.8,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.8,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7],\"low\":[1148.9,1148.9,1149.0,1149.0,1153.0,1153.0,1150.4,1150.2,1150.5,1150.0,1149.7,1149.5,1149.9,1149.9,1149.9,1150.0,1149.9,1150.8,1150.8,1150.8,1150.8,1150.0,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.8,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7],\"open\":[1148.9,1148.9,1149.0,1149.0,1153.0,1156.9,1150.6,1150.2,1150.5,1150.0,1149.7,1150.2,1149.9,1149.9,1149.9,1150.0,1149.9,1150.8,1150.8,1150.8,1150.8,1150.0,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.8,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7,1150.7],\"x\":[\"2016-01-04T10:01:00\",\"2016-01-04T10:02:00\",\"2016-01-04T10:03:00\",\"2016-01-04T10:04:00\",\"2016-01-04T10:05:00\",\"2016-01-04T10:06:00\",\"2016-01-04T10:07:00\",\"2016-01-04T10:08:00\",\"2016-01-04T10:09:00\",\"2016-01-04T10:10:00\",\"2016-01-04T10:11:00\",\"2016-01-04T10:12:00\",\"2016-01-04T10:13:00\",\"2016-01-04T10:14:00\",\"2016-01-04T10:15:00\",\"2016-01-04T10:16:00\",\"2016-01-04T10:17:00\",\"2016-01-04T10:18:00\",\"2016-01-04T10:19:00\",\"2016-01-04T10:20:00\",\"2016-01-04T10:21:00\",\"2016-01-04T10:22:00\",\"2016-01-04T10:23:00\",\"2016-01-04T10:24:00\",\"2016-01-04T10:25:00\",\"2016-01-04T10:26:00\",\"2016-01-04T10:27:00\",\"2016-01-04T10:28:00\",\"2016-01-04T10:29:00\",\"2016-01-04T10:30:00\",\"2016-01-04T10:31:00\",\"2016-01-04T10:32:00\",\"2016-01-04T10:33:00\",\"2016-01-04T10:34:00\",\"2016-01-04T10:35:00\",\"2016-01-04T10:36:00\",\"2016-01-04T10:37:00\",\"2016-01-04T10:38:00\",\"2016-01-04T10:39:00\",\"2016-01-04T10:40:00\",\"2016-01-04T10:41:00\",\"2016-01-04T10:42:00\",\"2016-01-04T10:43:00\",\"2016-01-04T10:44:00\",\"2016-01-04T10:45:00\",\"2016-01-04T10:46:00\",\"2016-01-04T10:47:00\",\"2016-01-04T10:48:00\",\"2016-01-04T10:49:00\",\"2016-01-04T10:50:00\"],\"type\":\"candlestick\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"rangeslider\":{\"visible\":false},\"title\":{\"text\":\"Time\"}},\"title\":{\"text\":\"Candlestick Chart for Yandex Stock Prices (First 50 Minutes of 2016)\"},\"yaxis\":{\"title\":{\"text\":\"Price\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('5346c7b6-6b40-4cc8-8a78-ae3bfc4650c0');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Define the path to the CSV file\n",
        "file_path = 'CLAI/data/YNDX_160101_161231.csv'\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Convert the <DATE> and <TIME> columns to a single datetime column\n",
        "df['datetime'] = pd.to_datetime(df['<DATE>'].astype(str) + df['<TIME>'].astype(str), format='%Y%m%d%H%M%S')\n",
        "\n",
        "# Select the first 50 rows for visualization\n",
        "df = df.head(50)\n",
        "\n",
        "# Create a candlestick chart\n",
        "fig = go.Figure(data=[go.Candlestick(x=df['datetime'],\n",
        "                                     open=df['<OPEN>'],\n",
        "                                     high=df['<HIGH>'],\n",
        "                                     low=df['<LOW>'],\n",
        "                                     close=df['<CLOSE>'])])\n",
        "\n",
        "# Update the layout of the chart\n",
        "fig.update_layout(title='Candlestick Chart for Yandex Stock Prices (First 50 Minutes of 2016)',\n",
        "                  xaxis_title='Time',\n",
        "                  yaxis_title='Price',\n",
        "                  xaxis_rangeslider_visible=False)\n",
        "\n",
        "# Show the chart\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUzGbUQpZaDn"
      },
      "source": [
        "#### What You See on the Chart:\n",
        "\n",
        "The candlestick chart for Yandex stock prices over the first 50 minutes of 2016 shows the following:\n",
        "- **X-axis:** Time intervals (each minute) during the selected period.\n",
        "- **Y-axis:** Stock prices.\n",
        "\n",
        "Each candlestick on the chart provides a snapshot of price activity for one minute:\n",
        "- **Green Candles:** Indicate that the stock price closed higher than it opened during that minute.\n",
        "- **Red Candles:** Indicate that the stock price closed lower than it opened.\n",
        "- **Upper and Lower Wicks:** Show the highest and lowest prices reached during each minute, providing a full range of price fluctuations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sk5KH7nOA6b"
      },
      "source": [
        "## Step 2: Define Constants and Enumerations\n",
        "\n",
        "In this step, we will define the constants and enumerations needed for our environment. We will start by setting default values for the number of bars and commission percentage. These constants help to maintain consistency and make the environment's parameters easily adjustable.\n",
        "\n",
        "Next, we encode all available actions as fields of an enumerator. We support a very simple set of actions with only three options:\n",
        "\n",
        "1. **Skip (0):** Do nothing and move to the next time step without making any transactions. This action allows the agent to observe market behavior without committing to a position, which can be useful for identifying trends or waiting for a more favorable moment to act.\n",
        "\n",
        "2. **Buy (1):** Purchase a single share if no share is currently held. If a share is already held, this action will have no effect. When buying a share, the agent incurs a commission, which is a small percentage of the current price. This action is crucial for the agent to take a position in the market and potentially profit from future price movements.\n",
        "\n",
        "3. **Close (2):** Sell the currently held share, if any, and close the existing position. If no share is held, this action will have no effect. Similar to buying, closing a position also incurs a commission. This action allows the agent to realize profits or cut losses by exiting the market.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLIpaUCE_adJ"
      },
      "outputs": [],
      "source": [
        "import enum\n",
        "\n",
        "DEFAULT_BARS_COUNT = 20\n",
        "DEFAULT_COMMISSION_PERC = 0.1 # in precents out of 100\n",
        "DEFAULT_BROCKER_FEE_PERC = 0.05 # in precents out of 100\n",
        "\n",
        "class Actions(enum.Enum):\n",
        "    Skip = 0\n",
        "    Buy = 1\n",
        "    Close = 2\n",
        "    Borrow_Short = 3\n",
        "    Return_Short = 4\n",
        "\n",
        "class Positions(enum.Enum):\n",
        "    Long = 1\n",
        "    Short = -1\n",
        "    Zero = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2hoTCKsOEjU"
      },
      "source": [
        "## Step 3: Implement the State Class\n",
        "\n",
        "The `State` class is a critical component that manages the state of the environment. It is responsible for maintaining the current state of the environment and providing the necessary data to the agent. The constructor of the `State` class accepts several arguments to customize the environment's behavior and observation representation:\n",
        "\n",
        "- **bars_count:** The number of past bars (time steps) to include in the observation. By default, this is set to 10 bars. This parameter controls how much historical data is provided to the agent at each step, helping it make informed decisions based on recent market trends.\n",
        "  \n",
        "- **commission_perc:** The commission percentage the agent has to pay when buying or selling a stock. By default, this is set to 0.1%. This parameter simulates the real-world cost of trading, which affects the agent's profitability and decision-making.\n",
        "\n",
        "- **reset_on_close:** A boolean flag that determines whether the environment should reset when the agent closes a position (sells a share). By default, this is set to True, meaning the episode will end when a position is closed. If set to False, the episode will continue until the end of the available data series, typically one year of data.\n",
        "\n",
        "- **reward_on_close:** A boolean flag that determines whether the reward is given only when a position is closed or distributed incrementally over each time step. This flexibility allows us to experiment with different reward structures and their impact on the agent's learning process.\n",
        "\n",
        "- **volumes:** A boolean flag indicating whether volume data should be included in the observation. Including volume data can provide additional insight into market activity and liquidity.\n",
        "\n",
        "The `State` class contains several key methods:\n",
        "\n",
        "1. **`reset(self, prices, offset):`** This method initializes the state with the given prices and offset. It ensures that the environment starts with no position held and resets the necessary internal variables. The `prices` parameter is an instance of `data.Prices`, which holds the price data arrays, and `offset` is the starting point in the time series from which to begin the simulation.\n",
        "\n",
        "2. **`shape(self):`** This property method returns the shape of the state representation. The shape varies depending on whether volume data is included. It accounts for the high, low, and close prices for each bar, as well as flags indicating the position status and relative profit.\n",
        "\n",
        "3. **`encode(self):`** This method converts the current state into a numpy array, making it suitable for input to the neural network. It compiles the high, low, and close prices of the past bars, the position flag, and the relative profit into a single array.\n",
        "\n",
        "4. **`_cur_close(self):`** This private method calculates the actual close price for the current bar, taking into account the relative close price and the open price. This calculation is essential for determining the profit or loss when closing a position.\n",
        "\n",
        "5. **`step(self, action):`** This method performs a step in the environment based on the agent's action. It updates the state, handles position changes (buying or closing a position), calculates the reward, and checks if the episode is done. The reward is adjusted for commission costs, and the position status is updated accordingly.\n",
        "\n",
        "By implementing these methods, the `State` class will provide a framework for managing the environment's state, processing agent actions, and encoding the state data for input into the agent's neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqOLuwK__nMe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "sys.path.append('/content/CLAI/lib')\n",
        "from lib import data\n",
        "\n",
        "class State:\n",
        "    def __init__(self, bars_count=10, commission_perc=0.1, reset_on_close=True, reward_on_close=True, volumes=True, init_capital=20_000, broker_fee=0.1):\n",
        "        assert isinstance(bars_count, int)\n",
        "        assert bars_count > 0\n",
        "        assert isinstance(commission_perc, float)\n",
        "        assert commission_perc >= 0.0\n",
        "        assert isinstance(reset_on_close, bool)\n",
        "        assert isinstance(reward_on_close, bool)\n",
        "\n",
        "        self.bars_count = bars_count # How many candles we look at\n",
        "\n",
        "        self.commission_perc = commission_perc\n",
        "        self.broker_fee_perc = broker_fee\n",
        "\n",
        "        self.reset_on_close = reset_on_close\n",
        "        self.reward_on_close = reward_on_close\n",
        "        self.volumes = volumes\n",
        "\n",
        "        self._offset = None # Start point to sim from\n",
        "        self._prices = None\n",
        "\n",
        "        self.have_position = Positions.Zero\n",
        "\n",
        "        self.open_price = 0\n",
        "        self.last_open = 0\n",
        "        self.relative_profit = 0\n",
        "        self.num_of_stocks = 0\n",
        "\n",
        "        self.bank = init_capital\n",
        "        self.init_bank = init_capital\n",
        "\n",
        "        self.debt = 0\n",
        "        self.actions_counter = {\"Short\":0,\"Long\":0}\n",
        "\n",
        "    def reset(self, prices, offset):\n",
        "        assert isinstance(prices, data.Prices)\n",
        "        assert offset >= self.bars_count - 1\n",
        "\n",
        "        self._prices = prices\n",
        "        self._offset = offset\n",
        "\n",
        "        self.have_position = Positions.Zero\n",
        "\n",
        "        self.open_price = 0\n",
        "        self.last_open = 0\n",
        "        self.relative_profit = 0\n",
        "        self.num_of_stocks = 0\n",
        "\n",
        "        self.bank = self.init_bank\n",
        "        self.debt = 0\n",
        "\n",
        "\n",
        "    @property\n",
        "    def shape(self):\n",
        "        # [h, l, c] * bars + position_flag + rel_profit (since open)\n",
        "        if self.volumes:\n",
        "            return (4 * self.bars_count + 2, )\n",
        "        else:\n",
        "            return (3 * self.bars_count + 2, )\n",
        "\n",
        "    def encode(self):\n",
        "        \"\"\"\n",
        "        Convert current state into numpy array.\n",
        "        \"\"\"\n",
        "        res = np.zeros(self.shape)\n",
        "\n",
        "        idx = 0\n",
        "        for bar in range(self.bars_count):\n",
        "            offset = self._offset - bar\n",
        "            res[idx] = self._prices.high[offset]\n",
        "            idx += 1\n",
        "            res[idx] = self._prices.low[offset]\n",
        "            idx += 1\n",
        "            res[idx] = self._prices.close[offset]\n",
        "            idx += 1\n",
        "            if self.volumes:\n",
        "                res[idx] = self._prices.volume[offset]\n",
        "                idx += 1\n",
        "\n",
        "        res[idx] = float(self.have_position)\n",
        "        idx += 1\n",
        "\n",
        "        res[idx] = self.relative_profit\n",
        "\n",
        "        return res\n",
        "\n",
        "    def _cur_close(self):\n",
        "        \"\"\"\n",
        "        Calculate real close price for the current bar\n",
        "        \"\"\"\n",
        "        open = self._prices.open[self._offset]\n",
        "        rel_close = self._prices.close[self._offset]\n",
        "        return open * (1.0 + rel_close)\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        Perform one step in our price, adjust offset, check for the end of prices\n",
        "        and handle position change\n",
        "        :param action:\n",
        "        :return: reward, done\n",
        "        \"\"\"\n",
        "        assert isinstance(action, Actions)\n",
        "        reward = 0.0\n",
        "        done = False\n",
        "\n",
        "        close               = self._cur_close()\n",
        "        open                = self._prices.open[self._offset]\n",
        "        commission          = self.commission_perc\n",
        "        fee                 = self.broker_fee_perc\n",
        "        self.num_of_stocks  = self.bank // (close * (100 + commission) / 100) if self.have_position == Positions.Zero else self.num_of_stocks\n",
        "        bought              = close  * self.num_of_stocks\n",
        "        cost                = bought * (100 + commission) / 100\n",
        "        borrowed            = bought * (100 - fee) / 100\n",
        "        need_return         = bought * (100 + fee) / 100\n",
        "\n",
        "        if self.have_position == Positions.Long:\n",
        "            self.relative_profit  = 100 * (bought - self.open_price) / self.init_bank\n",
        "            day_profit            = 100 * (bought - self.last_open) / self.init_bank\n",
        "        elif self.have_position == Positions.Short:\n",
        "            self.relative_profit  = 100 * (self.open_price - bought) / self.init_bank\n",
        "            day_profit            = 100 * (self.last_open  - bought) / self.init_bank\n",
        "        else:\n",
        "            self.relative_profit = 0\n",
        "            day_profit = 0\n",
        "\n",
        "        if action == Actions.Buy and self.have_position == Positions.Zero and self.num_of_stocks > 0:\n",
        "            self.have_position  = Positions.Long\n",
        "            self.open_price     = bought\n",
        "            self.last_open      = bought\n",
        "            self.bank -= cost\n",
        "            reward -= ((commission * bought) / self.init_bank)\n",
        "\n",
        "        elif action == Actions.Close and self.have_position == Positions.Long:\n",
        "          self.bank += (100 - commission) * bought / 100\n",
        "          reward -= ((commission * bought) / self.init_bank)\n",
        "          reward += self.relative_profit if self.reward_on_close else day_profit\n",
        "          self.have_position    = Positions.Zero\n",
        "          self.open_price       = 0\n",
        "          self.last_open        = 0\n",
        "          self.relative_profit  = 0\n",
        "          self.actions_counter[\"Long\"] += 1\n",
        "\n",
        "          if self.reset_on_close:\n",
        "              return reward, True\n",
        "\n",
        "        elif action == Actions.Borrow_Short and self.have_position == Positions.Zero and self.num_of_stocks > 0:\n",
        "            self.have_position  = Positions.Short\n",
        "            self.open_price     = bought\n",
        "            self.last_open      = bought\n",
        "            self.bank += borrowed\n",
        "            self.debt += borrowed\n",
        "            reward -= ((fee * bought) / self.init_bank)\n",
        "\n",
        "        elif action == Actions.Return_Short and self.have_position == Positions.Short:\n",
        "            self.bank -= need_return\n",
        "            reward -= ((fee * bought) / self.init_bank)\n",
        "            reward += self.relative_profit if self.reward_on_close else day_profit\n",
        "            if self.bank < 0:\n",
        "                reward += 100 * self.bank / self.init_bank\n",
        "                return reward, True\n",
        "            self.have_position    = Positions.Zero\n",
        "            self.open_price       = 0\n",
        "            self.last_open        = 0\n",
        "            self.relative_profit  = 0\n",
        "            self.debt             = 0\n",
        "            self.actions_counter[\"Short\"] += 1\n",
        "\n",
        "            if self.reset_on_close:\n",
        "                return reward, True\n",
        "\n",
        "        elif not self.reward_on_close and self.have_position:\n",
        "            self.last_open = bought\n",
        "            reward += day_profit\n",
        "\n",
        "\n",
        "        self._offset += 1\n",
        "        done = self._offset >= self._prices.open.shape[0]\n",
        "        if done:\n",
        "          self._offset = self.bars_count - 1\n",
        "        return reward, done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZN3Q8zPz_qjr"
      },
      "source": [
        "## Step 4: Implement the State1D Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCNKOsxgOIe7"
      },
      "source": [
        "The `State1D` class is a subclass of the `State` class, providing a specialized representation of the state suitable for 1D convolutional neural networks. While it inherits the core functionality from the `State` class, it overrides the shape and encoding methods to fit the requirements of 1D convolution operations.\n",
        "\n",
        "### Class: `State1D`\n",
        "\n",
        "#### Property: `shape`\n",
        "\n",
        "The `shape` property in the `State1D` class returns a different shape compared to the base `State` class. This shape is designed to be compatible with 1D convolutional neural networks, encoding the prices as a 2D matrix.\n",
        "\n",
        "- **Returns:**\n",
        "  - `tuple`: The shape of the state representation. If volumes are included, the shape is `(6, bars_count)`, otherwise, it is `(5, bars_count)`.\n",
        "\n",
        "#### Method: `encode`\n",
        "\n",
        "The `encode` method in the `State1D` class converts the current state into a 2D NumPy array, which is suitable for 1D convolutional operations. This representation organizes the price data into distinct rows for high, low, and close prices, with optional volume data and additional information about the position status and profit.\n",
        "\n",
        "- **Returns:**\n",
        "  - `numpy.ndarray`: The encoded state as a 2D array.\n",
        "\n",
        "- **Behavior:**\n",
        "  - Initializes a zero matrix with the shape determined by the `shape` property.\n",
        "  - Fills the matrix with high, low, and close prices from the specified number of past bars.\n",
        "  - Includes volume data if `volumes` is set to True.\n",
        "  - Adds flags for the position status (whether a share is held) and the relative profit if a position is held.\n",
        "\n",
        "The encoding process organizes the data into a matrix where each row corresponds to a different type of information (e.g., high prices, low prices), and each column represents a different bar (time step). This structure is analogous to different color channels in image data, making it well-suited for 1D convolutional layers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5bb7CbK_r3e"
      },
      "outputs": [],
      "source": [
        "class State1D(State):\n",
        "    \"\"\"\n",
        "    State with shape suitable for 1D convolution\n",
        "    \"\"\"\n",
        "    @property\n",
        "    def shape(self):\n",
        "        if self.volumes:\n",
        "            return (6, self.bars_count)\n",
        "        else:\n",
        "            return (5, self.bars_count)\n",
        "\n",
        "    def encode(self):\n",
        "        res = np.zeros(shape=self.shape, dtype=np.float32)\n",
        "        ofs = self.bars_count-1\n",
        "        temp = self._prices.high[self._offset-ofs:self._offset+1]\n",
        "        lent = len(temp)\n",
        "        res[0] = self._prices.high[self._offset-ofs:self._offset+1]\n",
        "        res[1] = self._prices.low[self._offset-ofs:self._offset+1]\n",
        "        res[2] = self._prices.close[self._offset-ofs:self._offset+1]\n",
        "        if self.volumes:\n",
        "            res[3] = self._prices.volume[self._offset-ofs:self._offset+1]\n",
        "            dst = 4\n",
        "        else:\n",
        "            dst = 3\n",
        "        if self.have_position != Positions.Zero:\n",
        "            res[dst] = [float(self.have_position.value)]*lent\n",
        "            res[dst+1] = [self.relative_profit]*lent\n",
        "        return res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oB0Brtot_udw"
      },
      "source": [
        "## Step 5: Implement the StocksEnv Class\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7aTsfpUOLf-"
      },
      "source": [
        "The `StocksEnv` class is a custom OpenAI Gym environment designed to simulate a stock market for training reinforcement learning (RL) agents. It allows agents to interact with a simulated market by observing stock prices, taking actions, and receiving rewards.\n",
        "\n",
        "### Class: `StocksEnv`\n",
        "\n",
        "#### Constructor: `__init__`\n",
        "\n",
        "The constructor sets up the environment with configurable parameters, such as stock prices, the number of past bars to include in observations, and whether to use a 1D convolutional neural network-compatible state representation. It defines the action and observation spaces and sets a random seed for reproducibility.\n",
        "\n",
        "#### Method: `reset`\n",
        "\n",
        "The `reset` method initializes the environment to a starting state. It selects an instrument from the available price data, sets the starting point in the time series, and resets the state. This provides the agent with an initial observation to begin the episode.\n",
        "\n",
        "#### Method: `step`\n",
        "\n",
        "The `step` method advances the environment by one time step based on the action taken by the agent. It updates the state, calculates the reward, and checks if the episode has ended. It returns the new observation, the reward, a flag indicating if the episode is over, and additional info about the current state.\n",
        "\n",
        "#### Method: `render`\n",
        "\n",
        "The `render` method is a placeholder for visualizing the environment. Currently, it does not perform any rendering but could be extended to display stock prices and agent actions.\n",
        "\n",
        "#### Method: `close`\n",
        "\n",
        "The `close` method is a placeholder for closing the environment. It currently does not perform any actions but could be used to clean up resources.\n",
        "\n",
        "#### Method: `seed`\n",
        "\n",
        "The `seed` method sets the random seed for the environment to ensure reproducibility. It returns the seed values used.\n",
        "\n",
        "#### Class Method: `from_dir`\n",
        "\n",
        "The `from_dir` class method creates an instance of `StocksEnv` using price data files from a specified directory. This simplifies setting up the environment with a new dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxlSK8DD_v-j"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "\n",
        "class StocksEnv(gym.Env):\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self, prices, bars_count=DEFAULT_BARS_COUNT,\n",
        "                 commission=DEFAULT_COMMISSION_PERC, reset_on_close=True, state_1d=False,\n",
        "                 random_ofs_on_reset=True, reward_on_close=True, volumes=False, broker_fee=DEFAULT_BROCKER_FEE_PERC):\n",
        "        # assert isinstance(prices, dict)\n",
        "        self._prices = prices\n",
        "        if state_1d:\n",
        "            self._state = State1D(bars_count, commission, reset_on_close, reward_on_close=reward_on_close,\n",
        "                                  volumes=volumes, broker_fee=broker_fee)\n",
        "        else:\n",
        "            self._state = State(bars_count, commission, reset_on_close, reward_on_close=reward_on_close,\n",
        "                                volumes=volumes, broker_fee=broker_fee)\n",
        "        self.action_space = gym.spaces.Discrete(len(Actions))\n",
        "        self.observation_space = gym.spaces.Box(low=-np.inf, high=np.inf, shape=self._state.shape, dtype=np.float32)\n",
        "        self.random_ofs_on_reset = random_ofs_on_reset\n",
        "        self.seed()\n",
        "\n",
        "    def reset(self):\n",
        "        # make selection of the instrument and it's offset. Then reset the state\n",
        "        if self.random_ofs_on_reset:\n",
        "            offset = self.np_random.integers(self._state.bars_count - 1, len(self._prices.open))\n",
        "        else:\n",
        "            offset = self._state.bars_count - 1\n",
        "        self._state.reset(self._prices, offset)\n",
        "        info = {}\n",
        "        return self._state.encode(), info\n",
        "\n",
        "    def step(self, action_idx):\n",
        "        action = Actions(action_idx)\n",
        "        reward, done = self._state.step(action)\n",
        "        obs = self._state.encode()\n",
        "        info = {}\n",
        "        return obs, reward, done, info\n",
        "\n",
        "    def render(self, mode='human', close=False):\n",
        "        pass\n",
        "\n",
        "    def close(self):\n",
        "        pass\n",
        "        #print(f\"Shorts: {self._state.action_space['Short']}, Longs: {self._state.action_space['Long']}\")\n",
        "\n",
        "    def seed(self, seed=None):\n",
        "        self.np_random, seed1 = seeding.np_random(seed)\n",
        "        seed2 = seeding.hash_seed(seed1 + 1) % 2 ** 31\n",
        "        return [seed1, seed2]\n",
        "\n",
        "    @classmethod\n",
        "    def from_dir(cls, data_dir, **kwargs):\n",
        "        prices = {file: data.load_relative(file) for file in data.price_files(data_dir)}\n",
        "        return StocksEnv(prices, **kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRQsOWmNqFdQ"
      },
      "source": [
        "## Step 6: Running the environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arG9fxTEqiKM"
      },
      "source": [
        "### Defining the Convolutional Model: DQNConv1D\n",
        "\n",
        "The `DQNConv1D` class defines a convolutional neural network model tailored for 1D time-series data, such as stock market prices. This model uses 1D convolutional layers to extract sequential features from the input data. The architecture comprises two main parts: the feature extraction layers and the fully connected heads. The feature extraction is performed through two 1D convolutional layers, each followed by ReLU activation to introduce non-linearity. These layers capture temporal patterns in the stock prices, which are essential for predicting future movements.\n",
        "\n",
        "After extracting features, the model splits into two fully connected (FC) heads: the value head and the advantage head. The value head outputs the estimated value of the current state, while the advantage head calculates the advantages for each possible action. This separation allows the model to differentiate between the overall quality of a state and the specific benefits of taking certain actions within that state. The final output combines these two components, helping the agent to make informed trading decisions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJF02rJ_qI7r",
        "outputId": "94c0319c-db1b-4287-a0f0-15b9b6aa2fa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning:\n",
            "\n",
            "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class DQNConv1D(nn.Module):\n",
        "    def __init__(self, shape, actions_n):\n",
        "        super(DQNConv1D, self).__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv1d(shape[0], 128, 5),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(128, 128, 5),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        out_size = self._get_conv_out(shape)\n",
        "\n",
        "        self.fc_val = nn.Sequential(\n",
        "            nn.Linear(out_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 1)\n",
        "        )\n",
        "\n",
        "        self.fc_adv = nn.Sequential(\n",
        "            nn.Linear(out_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, actions_n)\n",
        "        )\n",
        "\n",
        "    def _get_conv_out(self, shape):\n",
        "        o = self.conv(torch.zeros(1, *shape))\n",
        "        return int(np.prod(o.size()))\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv_out = self.conv(x).view(x.size()[0], -1)\n",
        "        val = self.fc_val(conv_out)\n",
        "        adv = self.fc_adv(conv_out)\n",
        "        return val + adv - adv.mean(dim=1, keepdim=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi_gwdgQQu6"
      },
      "source": [
        "Testing the environment involves several key steps. First, we load and preprocess the stock price data to ensure it fits the input requirements of both the model and the `StocksEnv` environment. Next, we initialize the environment with the preprocessed data, setting up the configuration parameters like the number of past bars to include in each observation and whether to use volume data.\n",
        "\n",
        "Once the environment is set up, we create an instance of the `DQNConv1D` model, specifying the input shape and the number of actions. The model is then trained by allowing it to interact with the environment: taking actions, receiving rewards, and updating its parameters based on the outcomes. An optimizer adjusts the model's weights to improve performance over time. Periodic evaluation during training ensures that the model is learning effectively.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WQwWX2VVJsc"
      },
      "source": [
        "### Training the Convolutional Model\n",
        "\n",
        "#### Epsilon-Greedy Exploration\n",
        "\n",
        "We employ an epsilon-greedy strategy for action selection to balance exploration and exploitation. Initially, the epsilon value is set to 1.0, encouraging the agent to explore a wide range of actions. Over the first one million steps, epsilon linearly decays to 0.1, gradually shifting the agent's focus towards exploiting the knowledge it has gained to make more informed decisions. This approach ensures that the agent explores sufficiently early on to discover various strategies and refines its decision-making process over time.\n",
        "\n",
        "#### Experience Replay Buffer\n",
        "\n",
        "A simple experience replay buffer of size 100,000 stores the agent's transitions (state, action, reward, next state). The buffer is initially populated with 10,000 transitions before training begins to ensure a diverse set of experiences for learning. During training, batches of experiences are randomly sampled from this buffer to break the temporal correlations and provide more stable and robust learning updates to the model. This technique helps in reducing overfitting and improves the generalization of the learned policies.\n",
        "\n",
        "#### Q-Value Dynamics Monitoring\n",
        "\n",
        "Every 1,000 steps, the mean Q-value for a fixed set of states is calculated. This periodic evaluation helps monitor the dynamics of the Q-values throughout the training process, providing insights into how the model's predictions are evolving. Tracking these values is crucial for understanding the learning progression and making necessary adjustments to the training parameters if required.\n",
        "\n",
        "#### Periodic Validation\n",
        "\n",
        "To ensure that the model generalizes well and does not overfit the training data, we perform validation every 100,000 steps. During validation, the agent plays 100 episodes using both the training data and previously unseen stock price data. Various characteristics of the orders are recorded in TensorBoard, including mean profit, the average number of bars held, and the share held count. These metrics help identify overfitting by comparing performance on training and validation datasets. If the model performs significantly better on the training data compared to the validation data, it indicates overfitting, prompting adjustments in the training regimen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eVgkW8wDuOo"
      },
      "source": [
        "Now we will define the following parameters for the training:\n",
        "\n",
        "#### Training Parameters\n",
        "\n",
        "- **BATCH_SIZE = 32:** This variable sets the number of training samples used in one iteration of the model training process. A batch size of 32 means that the model will update its weights after processing 32 samples from the replay buffer.\n",
        "\n",
        "- **BARS_COUNT = 50:** This specifies the number of past time steps (bars) that the model uses as input for making predictions. In this context, each bar represents one minute of trading data.\n",
        "\n",
        "- **TARGET_NET_SYNC = 1000:** This defines the frequency (in steps) at which the target network's weights are updated to match the main network's weights. The target network is used to stabilize training by providing consistent Q-value estimates.\n",
        "\n",
        "- **DEFAULT_STOCKS = \"CLAI/data/YNDX_160101_161231.csv\":** This is the default file path for the stock data used for training. It contains historical price data for Yandex stock for the year 2016.\n",
        "\n",
        "- **DEFAULT_VAL_STOCKS = \"CLAI/data/YNDX_150101_151231.csv\":** This is the default file path for the stock data used for validation. It contains historical price data for Yandex stock for the year 2015.\n",
        "\n",
        "#### Hyperparameters\n",
        "\n",
        "- **GAMMA = 0.99:** The discount factor used in the Q-learning algorithm. It determines the importance of future rewards. A value of 0.99 means that future rewards are considered almost as important as immediate rewards.\n",
        "\n",
        "- **REPLAY_SIZE = 100000:** The maximum size of the experience replay buffer. This buffer stores past experiences (state, action, reward, next state) to be used for training the model.\n",
        "\n",
        "- **REPLAY_INITIAL = 10000:** The number of experiences to collect before starting the training process. This ensures that the replay buffer has enough data to sample from when training begins.\n",
        "\n",
        "- **REWARD_STEPS = 2:** The number of steps to consider when computing the reward for an action. This allows the agent to account for delayed rewards, which can be crucial in a trading environment.\n",
        "\n",
        "- **LEARNING_RATE = 0.0001:** The rate at which the model updates its weights during training. A smaller learning rate means that the model makes smaller adjustments to its weights, which can lead to more stable training.\n",
        "\n",
        "#### Evaluation and Exploration\n",
        "\n",
        "- **STATES_TO_EVALUATE = 1000:** The number of states used to evaluate the performance of the model during training. This helps monitor the model's progress and stability.\n",
        "\n",
        "- **EVAL_EVERY_STEP = 1000:** The frequency (in steps) at which the model's performance is evaluated during training. Regular evaluations help track improvements and detect potential issues early.\n",
        "\n",
        "- **EPSILON_START = 1.0:** The initial value of epsilon in the epsilon-greedy exploration strategy. Epsilon determines the probability of choosing a random action versus the action suggested by the model. An epsilon of 1.0 means the agent will explore by choosing random actions initially.\n",
        "\n",
        "- **EPSILON_STOP = 0.1:** The final value of epsilon after it has decayed over time. An epsilon of 0.1 means the agent will still explore occasionally, but mostly follow the model's suggestions.\n",
        "\n",
        "- **EPSILON_STEPS = 1000000:** The number of steps over which epsilon decays from its initial value to its final value. This gradual decay balances exploration and exploitation as training progresses.\n",
        "\n",
        "#### Checkpoints and Validation\n",
        "\n",
        "- **CHECKPOINT_EVERY_STEP = 100000:** The frequency (in steps) at which the model's weights are saved to a checkpoint file. Checkpoints allow you to resume training from a specific point or analyze the model's performance at different stages of training.\n",
        "\n",
        "- **VALIDATION_EVERY_STEP = 12000:** The frequency (in steps) at which the model is validated using a separate validation dataset. Regular validation helps ensure that the model generalizes well to unseen data and prevents overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqOdPuzIDBUF",
        "outputId": "03b396c6-ad68-4818-fa7d-90b8912ca033"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning:\n",
            "\n",
            "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#You can adjust the numbers depending on how long you want your training to be\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "BARS_COUNT = 50\n",
        "TARGET_NET_SYNC = 5_000\n",
        "DEFAULT_STOCKS = \"CLAI/data/YNDX_160101_161231.csv\"\n",
        "DEFAULT_VAL_STOCKS = \"CLAI/data/YNDX_150101_151231.csv\"\n",
        "\n",
        "GAMMA = 0.98\n",
        "\n",
        "REPLAY_SIZE = 200_000\n",
        "REPLAY_INITIAL = 20_000\n",
        "\n",
        "REWARD_STEPS = 2\n",
        "\n",
        "LEARNING_RATE = 0.0002\n",
        "\n",
        "STATES_TO_EVALUATE = 1_000\n",
        "EVAL_EVERY_STEP = 1_000\n",
        "\n",
        "EPSILON_START = 1.0\n",
        "EPSILON_STOP = 0.1\n",
        "EPSILON_STEPS = 1_000_000\n",
        "\n",
        "TOTAL_STEPS = 1_000_000\n",
        "CHECKPOINT_EVERY_STEP = 50_000\n",
        "VALIDATION_EVERY_STEP = 25_000\n",
        "\n",
        "args_data = DEFAULT_STOCKS\n",
        "args_year = None  # Change to a specific year if needed\n",
        "args_valdata = DEFAULT_VAL_STOCKS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2GNnkHsEZlb"
      },
      "source": [
        "The next code block ensures that the results of the training run are saved properly:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAuLVidmDVBZ",
        "outputId": "b759c373-3a77-4acc-e829-245864f7c1c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run name is: test_run_20240930-1827\n",
            "Saving to: model/test_run_20240930-1827\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning:\n",
            "\n",
            "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Define the trigger\n",
        "use_google_drive = False  # Set this to True if you want to save the model weights in Google Drive\n",
        "\n",
        "\n",
        "# Get the current date and time in the specified format\n",
        "current_datetime = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
        "\n",
        "# Create the run name\n",
        "args_run = f\"test_run_{current_datetime}\"\n",
        "print(f\"Run name is: {args_run}\")\n",
        "\n",
        "if use_google_drive:\n",
        "    # Define the Google Drive path\n",
        "    drive.mount('/content/drive')\n",
        "    google_drive_path = '/content/drive/My Drive/CLAI-model' #You can change this path to any folder on your Drive\n",
        "\n",
        "    # Check if the folder exists\n",
        "    if not os.path.exists(google_drive_path):\n",
        "        # Create the folder if it doesn't exist\n",
        "        os.makedirs(google_drive_path)\n",
        "\n",
        "    # Define the full save path\n",
        "    saves_path = os.path.join(google_drive_path, args_run)\n",
        "else:\n",
        "    # Define the local save path\n",
        "    saves_path = os.path.join(\"model\", args_run)\n",
        "\n",
        "# Create the directory\n",
        "os.makedirs(saves_path, exist_ok=True)\n",
        "print(f\"Saving to: {saves_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "\n",
        "def validation_run2(env, net, Actions, episodes=100, device=\"cpu\", epsilon=0.02, commission=0.1):\n",
        "    stats = {\n",
        "        'episode_reward': [],\n",
        "        'episode_steps': [],\n",
        "        'order_profits': [],\n",
        "        'order_steps': [],\n",
        "    }\n",
        "\n",
        "    for episode in range(episodes):\n",
        "        obs = env.reset()[0]\n",
        "\n",
        "        total_reward = 0.0\n",
        "        position = None\n",
        "        position_steps = None\n",
        "        episode_steps = 0\n",
        "        while True:\n",
        "            obs_v = torch.tensor(np.array([obs])).to(device)\n",
        "            out_v = net(obs_v)\n",
        "\n",
        "            action_idx = out_v.max(dim=1)[1].item()\n",
        "            if np.random.random() < epsilon:\n",
        "                action_idx = env.action_space.sample()\n",
        "            action = Actions(action_idx)\n",
        "\n",
        "            close_price = env._state._cur_close()\n",
        "\n",
        "            if action == Actions.Buy and position is None:\n",
        "                position = close_price\n",
        "                position_steps = 0\n",
        "            elif action == Actions.Close and position is not None:\n",
        "                profit = close_price - position - (close_price + position) * commission / 100\n",
        "                profit = 100.0 * profit / position\n",
        "                stats['order_profits'].append(profit)\n",
        "                stats['order_steps'].append(position_steps)\n",
        "                position = None\n",
        "                position_steps = None\n",
        "\n",
        "            obs, reward, done, _ = env.step(action_idx)\n",
        "            total_reward += reward\n",
        "            episode_steps += 1\n",
        "            if position_steps is not None:\n",
        "                position_steps += 1\n",
        "            if done:\n",
        "                if position is not None:\n",
        "                    profit = close_price - position - (close_price + position) * commission / 100\n",
        "                    profit = 100.0 * profit / position\n",
        "                    stats['order_profits'].append(profit)\n",
        "                    stats['order_steps'].append(position_steps)\n",
        "                break\n",
        "\n",
        "        stats['episode_reward'].append(total_reward)\n",
        "        stats['episode_steps'].append(episode_steps)\n",
        "\n",
        "    return {key: np.mean(vals) for key, vals in stats.items()}"
      ],
      "metadata": {
        "id": "J1XnHFcMMK1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uynbR9v8EtIC"
      },
      "source": [
        "Now we can set up the environment and initialize the DQN agent for training on stock data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2XymHRhs3GSY"
      },
      "outputs": [],
      "source": [
        "import pdb\n",
        "import ptan\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from gym.utils import seeding\n",
        "from tensorboardX import SummaryWriter\n",
        "import importlib\n",
        "\n",
        "from lib import data, common, validation\n",
        "importlib.reload(common)\n",
        "\n",
        "\n",
        "if args_year is not None or os.path.isfile(args_data):\n",
        "    if args_year is not None:\n",
        "        stock_data = data.load_year_data(args_year)\n",
        "    else:\n",
        "        stock_data = data.load_relative(args_data)\n",
        "    env = StocksEnv(stock_data, bars_count=BARS_COUNT, reset_on_close=True, state_1d=True, volumes=False)\n",
        "    env_tst = StocksEnv(stock_data, bars_count=BARS_COUNT, reset_on_close=True, state_1d=True)\n",
        "elif os.path.isdir(args_data):\n",
        "    env = StocksEnv.from_dir(args_data, bars_count=BARS_COUNT, reset_on_close=True, state_1d=True)\n",
        "    env_tst = StocksEnv.from_dir(args_data, bars_count=BARS_COUNT, reset_on_close=True, state_1d=True)\n",
        "else:\n",
        "    raise RuntimeError(\"No data to train on\")\n",
        "env = gym.wrappers.TimeLimit(env, max_episode_steps=1000, new_step_api=True)\n",
        "\n",
        "val_data = data.load_relative(args_valdata)\n",
        "env_val = StocksEnv(val_data, bars_count=BARS_COUNT, reset_on_close=True, state_1d=True)\n",
        "\n",
        "writer = SummaryWriter(comment=\"-conv-\" + args_run)\n",
        "net = DQNConv1D(env.observation_space.shape, env.action_space.n).to(device)\n",
        "print(net)\n",
        "tgt_net = ptan.agent.TargetNet(net)\n",
        "selector = ptan.actions.EpsilonGreedyActionSelector(EPSILON_START)\n",
        "agent = ptan.agent.DQNAgent(net, selector, device=device)\n",
        "exp_source = ptan.experience.ExperienceSourceFirstLast(env, agent, GAMMA, steps_count=REWARD_STEPS)\n",
        "buffer = ptan.experience.ExperienceReplayBuffer(exp_source, REPLAY_SIZE)\n",
        "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "step_idx = 0\n",
        "eval_states = None\n",
        "best_mean_val = None\n",
        "\n",
        "with common.RewardTracker(writer, np.inf, group_rewards=100) as reward_tracker:\n",
        "    while step_idx < TOTAL_STEPS:\n",
        "        step_idx += 1\n",
        "        buffer.populate(1)\n",
        "        selector.epsilon = max(EPSILON_STOP, EPSILON_START - step_idx / EPSILON_STEPS)\n",
        "\n",
        "        new_rewards = exp_source.pop_rewards_steps()\n",
        "        if new_rewards:\n",
        "            reward_tracker.reward(new_rewards[0], step_idx, selector.epsilon)\n",
        "\n",
        "        if len(buffer) < REPLAY_INITIAL:\n",
        "            continue\n",
        "\n",
        "        if eval_states is None:\n",
        "            print(\"Initial buffer populated, start training\")\n",
        "            eval_states = buffer.sample(STATES_TO_EVALUATE)\n",
        "            eval_states = [np.array(transition.state, copy=False) for transition in eval_states]\n",
        "            eval_states = np.array(eval_states, copy=False)\n",
        "\n",
        "        if step_idx % EVAL_EVERY_STEP == 0 and eval_states is not None:\n",
        "            mean_val = common.calc_values_of_states(eval_states, net, device=device)\n",
        "            writer.add_scalar(\"values_mean\", mean_val, step_idx)\n",
        "            if best_mean_val is None or best_mean_val < mean_val:\n",
        "                if best_mean_val is not None:\n",
        "                    print(\"%d: Best mean value updated %.3f -> %.3f\" % (step_idx, best_mean_val, mean_val))\n",
        "                else:\n",
        "                    print(\"%d: New best mean value %.3f\" % (step_idx, mean_val))\n",
        "                best_mean_val = mean_val\n",
        "                torch.save(net.state_dict(), os.path.join(saves_path, \"mean_val-%.3f.data\" % mean_val))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        batch = buffer.sample(BATCH_SIZE)\n",
        "        loss_v = common.calc_loss(batch, net, tgt_net.target_model, GAMMA ** REWARD_STEPS, device=device)\n",
        "        loss_v.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if step_idx % TARGET_NET_SYNC == 0:\n",
        "            tgt_net.sync()\n",
        "\n",
        "        if step_idx % CHECKPOINT_EVERY_STEP == 0:\n",
        "            idx = step_idx // CHECKPOINT_EVERY_STEP\n",
        "            torch.save(net.state_dict(), os.path.join(saves_path, \"checkpoint-%3d.data\" % idx))\n",
        "\n",
        "        if step_idx % VALIDATION_EVERY_STEP == 0:\n",
        "            res = validation_run2(env_tst, net, Actions, device=device)\n",
        "            for key, val in res.items():\n",
        "                writer.add_scalar(key + \"_test\", val, step_idx)\n",
        "            res = validation_run2(env_val, net, Actions, device=device)\n",
        "            for key, val in res.items():\n",
        "                writer.add_scalar(key + \"_val\", val, step_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmcLUXxEWvqZ"
      },
      "source": [
        "Use the following code to plot average reward and episode length.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logfile = \"/content/runs/Sep25_15-59-25_3ecd4b8402c7-conv-test_run_20240925-1559/events.out.tfevents.1727279965.3ecd4b8402c7\"\n",
        "run_to_check = \"test_run_20240924-1517\""
      ],
      "metadata": {
        "id": "GKhNw2i9MYmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-8lavvZe9Kj"
      },
      "outputs": [],
      "source": [
        "from tensorboard.backend.event_processing import event_accumulator\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def extract_all_scalars(logfile):\n",
        "    ea = event_accumulator.EventAccumulator(logfile, size_guidance={event_accumulator.SCALARS: 0})\n",
        "    ea.Reload()\n",
        "    tags = ea.Tags()['scalars']\n",
        "    all_data = {}\n",
        "    for tag in tags:\n",
        "        scalars = ea.Scalars(tag)\n",
        "        data = pd.DataFrame(scalars)\n",
        "        all_data[tag] = data\n",
        "    return tags, all_data\n",
        "\n",
        "\n",
        "# Extract all scalar data and tags\n",
        "available_tags, all_scalar_data = extract_all_scalars(logfile)\n",
        "#You can use other tags for extra graphs to check your model performance in more detail\n",
        "\n",
        "# Function to plot specific tags\n",
        "def plot_tag_data(tag_data, xlabel, ylabel, title):\n",
        "    plt.figure()\n",
        "    plt.plot(tag_data['step'], tag_data['value'])\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.title(title)\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Plotting reward_100, steps_100, and values_mean\n",
        "plot_tags = {\n",
        "    'reward_100': ('Steps', 'Reward', 'Average reward over 100 episodes'),\n",
        "    'steps_100': ('Steps', 'Episode Length', 'Average steps per episode over 100 episodes'),\n",
        "    'values_mean': ('Steps', 'Value', 'Mean value of states'),\n",
        "}\n",
        "\n",
        "for tag, (xlabel, ylabel, title) in plot_tags.items():\n",
        "    if tag in all_scalar_data:\n",
        "        plot_tag_data(all_scalar_data[tag], xlabel, ylabel, title)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoLEoEDrJwPp"
      },
      "source": [
        "## Step 7: Evaluating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvdU0TAqBpLF"
      },
      "source": [
        "Finally, we will evaluate the trained model on a validation dataset to assess its generalization to new data. Performance metrics, such as total reward, profit, and loss, are used to determine the model's effectiveness in making trading decisions. This process ensures that the `StocksEnv` environment and the `DQNConv1D` model work cohesively to train an RL agent capable of profitable stock trading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEUrZAHqBrO4"
      },
      "outputs": [],
      "source": [
        "import pdb\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import numpy as np\n",
        "from lib import data\n",
        "from gym.utils import seeding\n",
        "\n",
        "EPSILON = 0.02\n",
        "\n",
        "def find_best_model(saves_path):\n",
        "    model_files = [f for f in os.listdir(saves_path) if f.startswith(\"mean_val-\") and f.endswith(\".data\")]\n",
        "    print(model_files)\n",
        "    def extract_value(f):\n",
        "        try:\n",
        "            return float(f.split('mean_val-')[1].split('.data')[0])\n",
        "        except ValueError:\n",
        "            return float('-inf')  # Return negative infinity if conversion fails\n",
        "    best_model_file = max(model_files, key=extract_value)\n",
        "    return os.path.join(saves_path, best_model_file)\n",
        "\n",
        "def run_model(data_file, model_file, bars, name, commission=0.1, use_conv=False, broker_fee=0.1):\n",
        "    prices = data.load_relative(data_file)\n",
        "    env = StocksEnv(prices, bars_count=bars, reset_on_close=False, commission=commission,\n",
        "                    state_1d=use_conv, random_ofs_on_reset=False, reward_on_close=True, volumes=False, broker_fee=broker_fee)\n",
        "    if use_conv:\n",
        "        net = DQNConv1D(env.observation_space.shape, env.action_space.n).to(device)\n",
        "    else:\n",
        "        net = models.SimpleFFDQN(env.observation_space.shape[0], env.action_space.n).to(device)\n",
        "\n",
        "    net.load_state_dict(torch.load(model_file, map_location=device))\n",
        "\n",
        "    obs = env.reset()[0]\n",
        "    start_price = env._state._cur_close()\n",
        "\n",
        "    total_reward = 0.0\n",
        "    step_idx = 0\n",
        "    long_indx = 0\n",
        "    short_indx = 0\n",
        "    rewards = []\n",
        "    while True:\n",
        "        step_idx += 1\n",
        "        obs_v = torch.tensor([obs], dtype=torch.float32).to(device)\n",
        "        out_v = net(obs_v)\n",
        "        action_idx = out_v.max(dim=1)[1].item()\n",
        "        if np.random.random() < EPSILON:\n",
        "            action_idx = env.action_space.sample()\n",
        "\n",
        "        action = Actions(action_idx)\n",
        "        obs, reward, done, _ = env.step(action_idx)\n",
        "        total_reward += reward\n",
        "        if reward != 0:\n",
        "          if action_idx ==2:\n",
        "            long_indx += 1\n",
        "          if action_idx == 4:\n",
        "            short_indx += 1\n",
        "            # print(f\"Reward: {reward}, Total: {total_reward}, Bank: {env._state.bank}, close: {env._state._cur_close()}, Num: {env._state.num_of_stocks}\")\n",
        "            # pdb.set_trace()\n",
        "            # x = 1\n",
        "\n",
        "        rewards.append(total_reward)\n",
        "        if step_idx % 100 == 0:\n",
        "            print(\"%d: reward=%.3f, bank=%.3f\" % (step_idx, total_reward, env._state.bank))\n",
        "        if done:\n",
        "            env.close()\n",
        "            break\n",
        "\n",
        "    plt.clf()\n",
        "    plt.plot(rewards)\n",
        "    plt.title(f\"Total reward, data={name}\")\n",
        "    plt.ylabel(\"Reward, %\")\n",
        "    plt.savefig(f\"rewards-{name}.png\")\n",
        "    print(f\"long : {long_indx},  short: {short_indx}\")\n",
        "\n",
        "# Automatically choose the best model file\n",
        "saves_path = os.path.join(\"model\", run_to_check)\n",
        "saves_path = \"/content/model/test_run_20240925-1559\"\n",
        "best_model_file = find_best_model(saves_path)\n",
        "print(f\"Using best model file: {best_model_file}\")\n",
        "\n",
        "# Run the model using the best DQNConv1D model\n",
        "run_model(data_file=\"CLAI/data/YNDX_160101_161231.csv\",\n",
        "          model_file=best_model_file,\n",
        "          bars=50,\n",
        "          name=\"test_run\",\n",
        "          commission=0.1,\n",
        "          use_conv=True,\n",
        "          broker_fee=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ekC8naD_yJg"
      },
      "source": [
        "## Step 8: Guidance Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9-LTPWbWupf"
      },
      "source": [
        "You may find answering the following questions helpful for your report. It is not mandatory, but can help you test yourself.\n",
        "\n",
        "1. **Environment Setup:**\n",
        "   - How does the `StocksEnv` class initialize the environment? What parameters does the constructor take, and how do they influence the environment's behavior?\n",
        "   - How does the environment handle the transition between different states? What mechanisms are in place to ensure the environment adheres to the Gym API specifications?\n",
        "\n",
        "2. **Observation Space:**\n",
        "   - What information does the agent observe at each time step? How are the open, high, low, and close prices represented, and why is this representation chosen?\n",
        "   - How does the inclusion or exclusion of volume data affect the agent’s ability to learn and make decisions?\n",
        "\n",
        "3. **Action Space and Rewards:**\n",
        "   - What actions can the agent take in the `StocksEnv` environment? How are these actions represented and processed?\n",
        "   - How is the reward system designed in this environment? What are the implications of using `reward_on_close` versus incremental rewards for each step?\n",
        "   - How does the agent's action space (buy, sell, hold) affect its learning process and decision-making? What challenges arise from this action space?\n",
        "\n",
        "4. **State Representation:**\n",
        "   - How does the `State` class encode the current environment state for the agent? What role do past bars (time steps) play in this representation?\n",
        "   - Discuss the importance of the 1D convolutional state representation in the context of sequential data such as stock prices.\n",
        "\n",
        "5. **Training and Validation:**\n",
        "   - What challenges did you encounter while training the network? How did you address issues related to overfitting or underfitting?\n",
        "   - Train the network on data from one of the years and then validate it on both years. Plot the results for both 2015 and 2016. What do you observe? Explain the results.\n",
        "   - Plot the results for 0% and 0.1% commission. Is your algorithm still profitable? Explain what happens and how commission impacts the agent's strategy.\n",
        "\n",
        "6. **General Understanding:**\n",
        "   - Why is it important to have a flexible and customizable environment for training reinforcement learning agents in stock trading?\n",
        "   - How do the concepts learned from this simulation environment apply to real-world financial markets?\n",
        "   - Reflect on the limitations of this simplified stock trading simulation. What additional factors or complexities would need to be considered in a real-world scenario?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf6vDMdx6d1F"
      },
      "source": [
        "# Part 2: Stock Environment Extention\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gay4S9X36jJz"
      },
      "source": [
        "### Task Description\n",
        "\n",
        "Building on the environment from Part 1, your objective is to create a new stock market environment that includes a pool of money for the agent to manage. In this extended environment, the agent will start with a fixed amount of money, which it can use to buy and sell stocks. The agent should be able to purchase multiple stocks in a single transaction, but only whole numbers of shares—no partial shares are allowed.\n",
        "\n",
        "### Key Requirements\n",
        "\n",
        "1. **Initial Capital**: The agent starts with a fixed sum of money.\n",
        "2. **Whole Number Stock Transactions**: The agent can buy or sell only whole numbers of stocks—partial shares are not allowed. For example, if the agent has \\$100 and the stock price is \\$10, it should be able to buy up to 10 shares.\n",
        "3. **Dynamic Stock Purchase**: The agent can buy multiple shares in a single transaction, limited by the available funds and the requirement that transactions involve whole shares only.\n",
        "4. **Action Space**: You have complete freedom in defining the action space. It can be discrete or continuous, depending on your chosen approach.\n",
        "5. **Edge Cases**: Handle all possible edge cases, such as:\n",
        "   - Preventing the agent from selling stocks it doesn’t own.\n",
        "   - Ensuring that only whole shares can be bought or sold.\n",
        "   - Properly calculating the remaining funds after a transaction, considering commission fees if applicable.\n",
        "\n",
        "### Implementation\n",
        "\n",
        "1. **Environment Design**: Extend the environment from Part 1 to include the pool of money and enforce whole-share transactions. Ensure that the agent’s actions adhere to the Gym API specifications. This environment must accurately track the agent’s holdings, available funds, and any profit or loss incurred.\n",
        "\n",
        "2. **Agent Modification**: After implementing the new environment, validate it by training an RL agent. You may choose to:\n",
        "   - Modify the existing agents from Part 1 to accommodate the new environment.\n",
        "   - Design a new agent from scratch that better suits the extended environment.\n",
        "\n",
        "3. **Performance Comparison**: Compare the results obtained in the new environment with those from Part 1. Analyze the agent’s performance, considering factors such as total profit, risk management, and strategy effectiveness.\n",
        "\n",
        "### Report Guidelines\n",
        "\n",
        "In your final report, include a detailed comparison between the results of the agent trained in Part 1 and the agent trained in this extended environment. Discuss how the introduction of a money pool and the restriction to whole-share transactions impact the agent's decision-making process, its ability to manage resources, and its overall profitability. Consider any challenges encountered during the implementation and how they were addressed.\n",
        "\n",
        "### Evaluation Criteria\n",
        "\n",
        "- **Correctness**: The environment must function as intended, adhering to the Gym API specifications.\n",
        "- **Comprehensive Implementation**: Proper handling of all edge cases and accurate tracking of the agent’s portfolio, available funds, and adherence to whole-share transactions.\n",
        "- **Performance**: Comparison of agent performance between Part 1 and Part 2, with analysis of the differences.\n",
        "- **Creativity and Research**: Innovative approaches to action space design, agent architecture, and environment dynamics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLOzp4C7CWNU"
      },
      "source": [
        "### Datasets for Training and Evaluation\n",
        "\n",
        "1. **Training Dataset**:\n",
        "   - Use the provided stock price data from `\"CLAI/data/YNDX_150101_151231.csv\"` to develop and train your RL agent. This dataset contains historical stock price data for the year 2015.\n",
        "\n",
        "2. **Validation Dataset**:\n",
        "   - The validation dataset `\"CLAI/data/YNDX_160101_161231.csv\"` is strictly for evaluating the performance of your trained model. It contains stock price data for the year 2016 and must not be used in the training process. This dataset should only be used to assess how well your model generalizes to unseen data.\n",
        "\n",
        "### Commission\n",
        "\n",
        "As in Part 1, you should evaluate your agent's performance under different commission rates. Specifically:\n",
        "- Provide results for a **0% commission** and a **0.1% commission**.\n",
        "- You may also explore higher commission rates if desired. This analysis will help you understand how transaction costs affect the agent's trading strategy and profitability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-sltCvXDE2D"
      },
      "outputs": [],
      "source": [
        "#TODO: implement your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4eARyv1O8du"
      },
      "source": [
        "# Export to PDF\n",
        "\n",
        "Run the following cell to download the notebook as a nicely formatted pdf file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k16BhdcreGNx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "outputId": "88f36f0d-8028-4388-93a3-0661f641f4d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning:\n",
            "\n",
            "`should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 3%\r\rReading package lists... 3%\r\rReading package lists... 4%\r\rReading package lists... 4%\r\rReading package lists... 40%\r\rReading package lists... 40%\r\rReading package lists... 41%\r\rReading package lists... 41%\r\rReading package lists... 47%\r\rReading package lists... 47%\r\rReading package lists... 56%\r\rReading package lists... 56%\r\rReading package lists... 58%\r\rReading package lists... 59%\r\rReading package lists... 59%\r\rReading package lists... 60%\r\rReading package lists... 60%\r\rReading package lists... 60%\r\rReading package lists... 60%\r\rReading package lists... 60%\r\rReading package lists... 60%\r\rReading package lists... 66%\r\rReading package lists... 66%\r\rReading package lists... 74%\r\rReading package lists... 74%\r\rReading package lists... 77%\r\rReading package lists... 77%\r\rReading package lists... 77%\r\rReading package lists... 77%\r\rReading package lists... 77%\r\rReading package lists... 77%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 95%\r\rReading package lists... 95%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 99%\r\rReading package lists... 99%\r\rReading package lists... 99%\r\rReading package lists... 99%\r\rReading package lists... Done\r\n",
            "\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree... 99%\r\rBuilding dependency tree... Done\r\n",
            "\rReading state information... 0% \r\rReading state information... 0%\r\rReading state information... Done\r\n",
            "pandoc is already the newest version (2.9.2.1-3ubuntu2).\n",
            "texlive is already the newest version (2021.20220204-1).\n",
            "texlive-latex-extra is already the newest version (2021.20220204-1).\n",
            "texlive-xetex is already the newest version (2021.20220204-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 54 not upgraded.\n",
            "File ‘colab_pdf.py’ already there; not retrieving.\n",
            "\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "[NbConvertApp] Converting notebook drive/MyDrive/Colab Notebooks/CLAI_236203_FINAL_PROJECT (1).ipynb to pdf\n",
            "/usr/local/lib/python3.10/dist-packages/nbconvert/filters/datatypefilter.py:41: UserWarning: Your element with mimetype(s) dict_keys(['text/html']) is not able to be represented.\n",
            "  warn(\n",
            "[NbConvertApp] Writing 207003 bytes to notebook.tex\n",
            "[NbConvertApp] Building PDF\n",
            "[NbConvertApp] Running xelatex 3 times: ['xelatex', 'notebook.tex', '-quiet']\n",
            "[NbConvertApp] Running bibtex 1 time: ['bibtex', 'notebook']\n",
            "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
            "[NbConvertApp] PDF successfully created\n",
            "[NbConvertApp] Writing 194595 bytes to /content/drive/MyDrive/CLAI_236203_FINAL_PROJECT (1).pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9393981a-bfd8-49cc-871c-0ca52533b0d7\", \"CLAI_236203_FINAL_PROJECT (1).pdf\", 194595)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File ready to be Downloaded and Saved to Drive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "!apt-get install texlive texlive-xetex texlive-latex-extra pandoc\n",
        "!wget -nc https://raw.githubusercontent.com/omershubi/colab-pdf/master/colab_pdf.py\n",
        "\n",
        "from colab_pdf import colab_pdf\n",
        "\n",
        "# If you saved the notebook in the default location in your Google Drive,\n",
        "#  and didn't change the name of the file, the code should work as is. If not, adapt accordingly.\n",
        "# E.g. in your case the file name may be \"Copy of XXXX.ipynb\"\n",
        "\n",
        "colab_pdf(file_name='CLAI_236203_FINAL_PROJECT (1).ipynb', notebookpath=\"drive/MyDrive/Colab Notebooks\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jBxNrY6JM1Y7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}